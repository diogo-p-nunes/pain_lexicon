{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec: How To Implement word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Pre-trained Embeddings\n",
    "\n",
    "Some other options:\n",
    "- `glove-twitter-{25/50/100/200}`\n",
    "- `glove-wiki-gigaword-{50/200/300}`\n",
    "- `word2vec-google-news-300`\n",
    "- `word2vec-ruscorpora-news-300`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp36-cp36m-macosx_10_9_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5.0 in /Users/jayachaturvedi/anaconda3/lib/python3.6/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /Users/jayachaturvedi/anaconda3/lib/python3.6/site-packages (from gensim) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /Users/jayachaturvedi/anaconda3/lib/python3.6/site-packages (from gensim) (1.1.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-4.1.2-py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 1.8.0\n",
      "    Uninstalling smart-open-1.8.0:\n",
      "      Successfully uninstalled smart-open-1.8.0\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 3.7.1\n",
      "    Uninstalling gensim-3.7.1:\n",
      "      Successfully uninstalled gensim-3.7.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "medcat 0.2.9.3 requires spacy==2.1.3, but you'll have spacy 2.3.5 which is incompatible.\u001b[0m\n",
      "Successfully installed gensim-3.8.3 smart-open-4.1.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0 is available.\n",
      "You should consider upgrading via the '/Users/jayachaturvedi/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install gensim\n",
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained word vectors using gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "wiki_embeddings = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.074065 ,  0.27331  ,  0.11436  , -0.021311 , -0.7097   ,\n",
       "        0.69676  , -0.63839  , -0.10449  , -0.046197 , -0.94039  ,\n",
       "       -0.45073  , -0.2913   ,  0.16654  ,  0.10863  ,  0.50075  ,\n",
       "       -0.35285  , -1.1068   , -0.24618  , -0.4846   , -0.28999  ,\n",
       "        0.26324  , -0.10728  , -1.3835   ,  0.67262  ,  0.090377 ,\n",
       "        1.4126   ,  0.62699  , -0.9212   ,  0.71476  , -0.4183   ,\n",
       "        0.36514  ,  0.12508  , -0.60492  ,  0.14183  , -0.75623  ,\n",
       "       -0.40986  , -0.073459 ,  0.73399  ,  0.20977  ,  0.20305  ,\n",
       "        0.22164  ,  0.3502   ,  0.13281  , -1.019    , -0.30507  ,\n",
       "        0.37541  ,  0.72874  , -0.025062 , -0.21775  , -0.63315  ,\n",
       "       -0.22306  ,  0.12251  ,  0.035594 ,  0.59439  ,  0.43194  ,\n",
       "       -1.7208   ,  0.24543  , -0.52877  ,  0.68096  ,  0.591    ,\n",
       "        0.99566  ,  0.87977  , -0.031954 , -0.095788 , -0.036024 ,\n",
       "        0.12737  ,  0.85311  , -1.157    , -0.15524  , -0.66628  ,\n",
       "       -0.3557   ,  0.10642  , -0.090021 ,  0.45239  ,  1.1023   ,\n",
       "        0.86737  , -0.44809  ,  0.27245  , -0.3117   ,  0.21427  ,\n",
       "        0.2168   , -0.0075989, -0.49981  ,  0.46884  , -2.3639   ,\n",
       "        0.13045  , -0.059145 ,  0.20188  , -1.0252   , -0.16551  ,\n",
       "       -0.33376  , -0.25941  ,  0.20809  ,  0.43591  ,  0.47631  ,\n",
       "        0.79786  ,  0.74458  , -0.39394  ,  0.98439  , -0.15101  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the word vector for \"king\" - \"pain\"\n",
    "wiki_embeddings['pain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lingering', 0.7641147375106812),\n",
       " ('mounting', 0.7182013988494873),\n",
       " ('widespread', 0.6965022087097168),\n",
       " ('concern', 0.6881173849105835),\n",
       " ('concerns', 0.6766042113304138),\n",
       " ('fears', 0.6710178852081299),\n",
       " ('worries', 0.6708651781082153),\n",
       " ('unrelenting', 0.6659743785858154),\n",
       " ('continuing', 0.6657591462135315),\n",
       " ('severe', 0.6639633178710938),\n",
       " ('chronic', 0.6589462757110596),\n",
       " ('worsening', 0.656125545501709),\n",
       " ('prolonged', 0.6560916900634766),\n",
       " ('nagging', 0.6553113460540771),\n",
       " ('serious', 0.6525529623031616)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the words most similar to pain based on the trained word vectors\n",
    "wiki_embeddings.most_similar('persistent', topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5015517"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings.similarity('persistent','pain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6589464"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings.similarity('persistent','chronic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data and clean up column names\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('../../../data/spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[dun, say, so, early, hor, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, don, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            text_clean  \n",
       "0  [go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...  \n",
       "1                                                                          [ok, lar, joking, wif, oni]  \n",
       "2  [free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...  \n",
       "3                                                       [dun, say, so, early, hor, already, then, say]  \n",
       "4                                [nah, don, think, he, goes, to, usf, he, lives, around, here, though]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data using the built in cleaner in gensim\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'],\n",
    "                                                    messages['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the word2vec model\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05425125,  0.04536858, -0.09595686, -0.02699764,  0.11971134,\n",
       "        0.10338762, -0.03818981, -0.01448795,  0.0171045 ,  0.00511975,\n",
       "        0.01045221, -0.00677045, -0.12050592,  0.11097632, -0.04719375,\n",
       "       -0.02802079,  0.01247429, -0.06322849,  0.06611794,  0.07224897,\n",
       "       -0.02086301,  0.016499  ,  0.02015498,  0.00358362,  0.08886525,\n",
       "       -0.099216  ,  0.06923407,  0.01566726, -0.05832795,  0.03870581,\n",
       "       -0.02199215,  0.03693705, -0.00661952, -0.04715456,  0.07135164,\n",
       "       -0.00723605,  0.02134361, -0.09508089, -0.00362955, -0.03568636,\n",
       "        0.05925028, -0.01528659, -0.04217548,  0.01903476, -0.02175902,\n",
       "       -0.08289368, -0.06005706, -0.02793312,  0.06268803,  0.06778472,\n",
       "       -0.03594127,  0.11335944, -0.06159783, -0.0157827 , -0.03330815,\n",
       "       -0.00814747, -0.08040741, -0.02449049, -0.02535428, -0.02809742,\n",
       "        0.03898891, -0.03665545, -0.0125957 ,  0.04661012, -0.04162746,\n",
       "       -0.04639079, -0.04960034, -0.07714609,  0.04107031, -0.09253732,\n",
       "       -0.01676098,  0.02474785,  0.00722534, -0.03722506,  0.00060164,\n",
       "        0.04112774, -0.01472258, -0.020603  ,  0.00837047, -0.02261345,\n",
       "       -0.08669405, -0.03500905, -0.0035227 ,  0.03014234,  0.04523816,\n",
       "        0.01592521,  0.02888482, -0.02136791,  0.00993793, -0.00678027,\n",
       "       -0.08812838, -0.00462495, -0.00448728,  0.0099775 ,  0.08469445,\n",
       "       -0.02770836,  0.02969605, -0.04327951,  0.00635819, -0.02229221],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the word vector for \"king\" base on our trained model\n",
    "w2v_model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('show', 0.9984022974967957),\n",
       " ('being', 0.9983983039855957),\n",
       " ('coming', 0.9983887672424316),\n",
       " ('working', 0.9983633756637573),\n",
       " ('watching', 0.9983620643615723),\n",
       " ('boy', 0.998355507850647),\n",
       " ('gonna', 0.9983476400375366),\n",
       " ('poly', 0.9983355402946472),\n",
       " ('how', 0.9983333945274353),\n",
       " ('friends', 0.9983316659927368)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most similar words to \"king\" based on word vectors from our trained model\n",
    "w2v_model.wv.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
